{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1f8a72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-e31131b54a4d>, line 238)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-e31131b54a4d>\"\u001b[1;36m, line \u001b[1;32m238\u001b[0m\n\u001b[1;33m    print(\"Number of Outputs = \" + str(math.sqrt(len(M.layers[num - 1].output))) + \"x\" + str(math.sqrt(len(M.layers[num - 1].output))) + \" = \" + str(len(M.layers[num - 1].output)))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "from math import *\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import numpy\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h',\n",
    "            'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', \n",
    "            'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "            'y', 'z', '0', '1', '2', '3', '4', '5',\n",
    "            '6', '7', '8', '9']\n",
    "\n",
    "def toBlackWhiteBinary(img):\n",
    "    \n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            if img[i][j] < 128:\n",
    "                img[i][j] = 0\n",
    "                \n",
    "            else:\n",
    "                img[i][j] = 255\n",
    "            \n",
    "    \n",
    "    return img\n",
    "\n",
    "def makeBinaryImages():                \n",
    "    for i in alphabet:\n",
    "        path = list(\"./CharDataset1/x.jpg\")\n",
    "        path[len(path) - 5] = str(i)\n",
    "        path = \"\".join(path)\n",
    "        print(path, \"\\n\")\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        print(type(img))\n",
    "        img = toBlackWhiteBinary(img)\n",
    "        cv2.imwrite(path, img)\n",
    "        \n",
    "def ImageToArray(img):\n",
    "    final = []\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[1])):\n",
    "            final.append(img[i][j])\n",
    "            \n",
    "    for i in range(len(final)):\n",
    "        if final[i] == 255:\n",
    "            final[i] = 1\n",
    "        else:\n",
    "            final[i] = 0\n",
    "    return final\n",
    "\n",
    "def compareImage(Original, Output):\n",
    "    mismatch = 0\n",
    "    for i in range(len(Original)):\n",
    "        if Output[i] != Original[i]:\n",
    "            mismatch += 1\n",
    "    return mismatch / len(Original)\n",
    "\n",
    "#gets all dataset 1 images\n",
    "def DataSetOfAllImages(num):\n",
    "    dataset = []\n",
    "    for i in alphabet:\n",
    "        path = list(\"./CharDatasetx/y.jpg\")\n",
    "        path[len(path) - 5] = str(i)\n",
    "        path[13] = str(num)\n",
    "        path = \"\".join(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img.setflags(write = 1)\n",
    "       \n",
    "        dataset.append(ImageToArray(img))\n",
    "    return dataset\n",
    "\n",
    "def Threshold(Arr):\n",
    "    newArr = []\n",
    "    for i in Arr:\n",
    "        if i > 0.5:\n",
    "            newArr.append(1)\n",
    "        else:\n",
    "            newArr.append(0)\n",
    "    return newArr\n",
    "\n",
    "def ThresholdResultArrays(arrs):\n",
    "    newArr = []\n",
    "    for i in arrs:\n",
    "        newArr.append(Threshold(i))\n",
    "    return newArr\n",
    "\n",
    "def CountWhitePixels(img):\n",
    "    count = 0\n",
    "    for i in img:\n",
    "        if i == 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def ComputeFh(correctImage, Output):\n",
    "    TotalBlackPixels = 0\n",
    "    TotalCorrectPixels = 0\n",
    "    \n",
    "    for i in range(len(correctImage)):\n",
    "        if correctImage[i] == 1:\n",
    "            TotalBlackPixels += 1\n",
    "            if(Output[i] == 1):\n",
    "                TotalCorrectPixels += 1\n",
    "    \n",
    "    if TotalBlackPixels == 0:\n",
    "        TotalBlackPixels += 1\n",
    "        \n",
    "    return TotalCorrectPixels / TotalBlackPixels\n",
    "\n",
    "def ComputeFhArray(correctImages, OutputImages):\n",
    "    fhArr = []\n",
    "    for i in range(len(correctImages)):\n",
    "        fhArr.append(ComputeFh(correctImages[i], OutputImages[i]))\n",
    "    return fhArr\n",
    "\n",
    "def ComputeFfa(correctImage, Output):\n",
    "    TotalWrongPixels = 0\n",
    "    \n",
    "    for i in range(len(correctImage)):\n",
    "        if (Output[i] == 1) and (correctImage[i] != 1):\n",
    "            TotalWrongPixels += 1\n",
    "    \n",
    "    if CountWhitePixels(correctImage) == 0:\n",
    "        return TotalWrongPixels\n",
    "    \n",
    "    return TotalWrongPixels / CountWhitePixels(correctImage)\n",
    "\n",
    "def ComputeFfaArray(correctImages, OutputImages):\n",
    "    ffaArr = []\n",
    "    for i in range(len(correctImages)):\n",
    "        ffaArr.append(ComputeFfa(correctImages[i], OutputImages[i]))\n",
    "    return ffaArr\n",
    "\n",
    "#Images would be X\n",
    "def Perturb(images, mean, std_dev, cs):\n",
    "    \n",
    "    NoiseCorruptedImages = []\n",
    "    \n",
    "    for i in images:\n",
    "        currentImage = i\n",
    "        \n",
    "        mean, std_dev = mean, std_dev\n",
    "        \n",
    "        num = round(cs * len(i))\n",
    "\n",
    "        sample = numpy.random.normal(mean, std_dev, num)\n",
    "\n",
    "        RandomImageIndexes = random.sample(range(0, 255), num)\n",
    "        \n",
    "        sampleIndex = 0\n",
    "        \n",
    "        for j in RandomImageIndexes:\n",
    "            currentImage[j] += sample[sampleIndex]\n",
    "            sampleIndex += 1\n",
    "        NoiseCorruptedImages.append(currentImage)\n",
    "        \n",
    "    return ThresholdResultArrays(NoiseCorruptedImages)\n",
    "            \n",
    "    \n",
    "    \n",
    "def Model(X, y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim = 256, activation='relu'))\n",
    "    #model.add(Dense(256, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    model.fit(X, y, epochs=10, batch_size=2, verbose = True)\n",
    "    return model\n",
    "\n",
    "def MultiLayerModel(X, y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim = 256, activation='relu'))\n",
    "    model.add(Dense(256, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    model.fit(X, y, epochs=20, batch_size=2, verbose = True)\n",
    "    return model\n",
    "\n",
    "def SixteenAutoAssociativeDeepModel(X, y, _epochs, _batch_size, V = False):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(128, input_dim = 256, activation='relu'))\n",
    "    model.add(Dense(128, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(Dense(128, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(Dense(128, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    model.add(Dense(256, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    model.fit(X, y, epochs=_epochs, batch_size=_batch_size, verbose = V)\n",
    "    return model\n",
    "\n",
    "def RunAnalysis(X, Y, model, plotTitle=None):\n",
    "    \n",
    "    FhArray = ComputeFhArray(X, Y)\n",
    "    FfaArray = ComputeFfaArray(X, Y)\n",
    "    \n",
    "    \n",
    "    #print(FhArray)\n",
    "    #print(FfaArray)\n",
    "    \n",
    "    plt.scatter(FfaArray, FhArray)\n",
    "    plt.title(plotTitle)\n",
    "    plt.xlabel(\"Ffa\")\n",
    "    plt.ylabel(\"Fh\")\n",
    "    plt.show()\n",
    "    \n",
    "    return [FhArray, FfaArray]\n",
    "\n",
    "def Tabulate(FhArrays, FfaArrays, dim, M, num = 3):\n",
    "    #([\"Image 0\",FhStdDev0, FfaStdDev0, ..., FhStdDev0.1, FfaStdDev0.1])\n",
    "    table = []\n",
    "    for i in range(10):\n",
    "        newEntry = []\n",
    "        newEntry.append(str(i))\n",
    "        for j in range(len(FhArrays)):\n",
    "            newEntry.append(str(round(FhArrays[i][j], 2)))\n",
    "            newEntry.append(str(round(FfaArrays[i][j], 2)))\n",
    "        table.append(newEntry)\n",
    "        \n",
    "    print(\"Number of Inputs = \" + str(dim) + \"x\" + str(dim) + \" = \" + str(dim * dim))\n",
    "    print(\"Number of Weights in an Equivalent Single-Layer Perceptron = \" + str(dim) + \"x\" + str(dim) + \" = \" + str(dim * dim) + \"K\")\n",
    "    print(\"Number of Hidden Layers in This DNN = \" + str(num))\n",
    "    \n",
    "    for i in range(num):\n",
    "        print(\"Number of Weights in Hidden Layer \" + str(i) + \" = \" + str((len(M.layers[i].output) * len(M.layers[i + 1].output) + len(M.layers[i + 1].output) * len(M.layers[i + 2].output))\n",
    "        \n",
    "    \n",
    "    print(\"Number of Outputs = \" + str(math.sqrt(len(M.layers[num - 1].output))) + \"x\" + str(math.sqrt(len(M.layers[num - 1].output))) + \" = \" + str(len(M.layers[num - 1].output)))\n",
    "    \n",
    "    print(tabulate(table, headers = [\"Image\", \"Fh 0\", \"Ffa 0\", \"Fh 0.001\", \"Ffa 0.001\",\n",
    "                                     \"Fh 0.002\", \"Ffa 0.002\", \"Fh 0.003\", \"Ffa 0.003\", \n",
    "                                     \"Fh 0.005\", \"Ffa 0.005\", \"Fh 0.01\", \"Ffa 0.01\", \n",
    "                                    \"Fh 0.02\", \"Ffa 0.02\", \"Fh 0.03\", \"Ffa 0.03\", \n",
    "                                     \"Fh 0.05\", \"Ffa 0.05\", \"Fh 0.1\", \"Ffa 0.1\"]))\n",
    "    \n",
    "def FinalPlot(FhArrays, FfaArrays, Std_Devs):\n",
    "    \n",
    "    for i in range(len(FhArrays)):\n",
    "        for j in range(len(FhArrays[i])):\n",
    "            for k in Std_Devs:\n",
    "                plt.scatter(k, FhArrays[i][j], color='blue')\n",
    "                plt.scatter(k, FfaArrays[i][j], color = 'red')\n",
    "    plt.title(\"Graph of Fh and Ffa vs. Noise Standard Deviation for noise-corrupted Alphanumeric Imagery (16x16 pixels) for Autoassociative Single-Layer Perceptron\")\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    plt.xlabel(\"Gaussian Noise Level (stdev, at 10 pct xsecn)\")\n",
    "    plt.xlim([0, 0.1])\n",
    "    #plt.xticks(numpy.arange(0, 0.1, 0.001))\n",
    "    \n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel(\"Fh and Ffa\")\n",
    "    \n",
    "    plt.legend([\"Blue = Fh\", \"Red = Ffa\"])\n",
    "    \n",
    "    plt.show()\n",
    "        \n",
    "def RunExperiment(X, M):\n",
    "    #print(X[1])\n",
    "    print(\"Predicting Dataset\")\n",
    "    Y = ThresholdResultArrays(M.predict(X))\n",
    "    print(\"Running Analysis\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    stdDevs = [0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "    cs = [0.1, 0.2, 0.25, 0.3, 0.35]\n",
    "    \n",
    "    \n",
    "    print(\"Testing with Noise\")\n",
    "    \n",
    "    \n",
    "    for j in cs:\n",
    "        a = RunAnalysis(X, Y, M, \"Fh Vs. Ffa 0 Std. Dev \" + \" and Cross Section = \" + str(j))\n",
    "        FhArrays = []\n",
    "        FfaArrays = []\n",
    "        FhArrays.append(a[0])\n",
    "        FfaArrays.append(a[1])\n",
    "        for i in stdDevs:\n",
    "            NoisyImages = Perturb(X, 0, i, j)\n",
    "            a = RunAnalysis(NoisyImages, Y, M, \"Fh Vs. Ffa Noise with Std Dev = \" + str(i) + \" and Cross Section = \" + str(j))\n",
    "            FhArrays.append(a[0])\n",
    "            FfaArrays.append(a[1])\n",
    "            \n",
    "        Tabulate(FhArrays, FfaArrays, 16, M, 3)\n",
    "    \n",
    "   \n",
    "        \n",
    "    \n",
    "    stdDevs = [0] + stdDevs\n",
    "    #FinalPlot(FhArrays, FfaArrays, stdDevs)\n",
    "\n",
    "\n",
    "    \n",
    "def main():\n",
    "            \n",
    "    X = numpy.array(DataSetOfAllImages(1))\n",
    "    X2 = numpy.array(DataSetOfAllImages(2))\n",
    "    y = X\n",
    "    \n",
    "    M = SixteenAutoAssociativeDeepModel(X, y, 100, 2, True)\n",
    "    print(\"Running Experiment with Original Dataset\")\n",
    "    RunExperiment(X, M)\n",
    "    print(\"Running Experiment with Dataset #2\")\n",
    "    RunExperiment(X2, M)\n",
    "    \n",
    "    \n",
    "        \n",
    "main()\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c71e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
